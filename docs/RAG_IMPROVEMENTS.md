# üöÄ Melhorias no Sistema RAG

## ‚úÖ O que foi implementado

### 1Ô∏è‚É£ **Depend√™ncias Instaladas**
- ‚úÖ `langchain` - Framework para trabalhar com LLMs
- ‚úÖ `@langchain/textsplitters` - Text splitters avan√ßados para chunking inteligente

### 2Ô∏è‚É£ **Schema do Banco de Dados** (Migration 007)
- ‚úÖ Adicionado campo `content_with_context` - Armazena chunk com contexto para debugging
- ‚úÖ Melhorado campo `metadata` (JSONB) - Metadata rica em cada chunk
- ‚úÖ Adicionado campos `file_size`, `file_type`, `chunk_index` se n√£o existiam
- ‚úÖ Criado √≠ndice GIN para full-text search: `idx_knowledge_content_fts`
- ‚úÖ Criado √≠ndice GIN para metadata: `idx_knowledge_metadata_gin`
- ‚úÖ Criado √≠ndice composto: `idx_knowledge_agent_chunk`
- ‚úÖ Fun√ß√£o de busca h√≠brida: `search_knowledge_hybrid()` - Combina similaridade vetorial + keywords
- ‚úÖ Fun√ß√£o de busca por keywords: `search_knowledge_by_keywords()`

### 3Ô∏è‚É£ **Melhorias no Chunking** (`embedding.service.ts`)
**Antes:**
```typescript
// Chunking simples por caracteres
export function chunkText(text: string, maxChunkSize = 1000, overlap = 200)
```

**Depois:**
```typescript
// RecursiveCharacterTextSplitter do LangChain
export async function chunkText(text: string, maxChunkSize = 800, overlap = 200)
```

**Melhorias:**
- ‚úÖ Usa `RecursiveCharacterTextSplitter` do LangChain
- ‚úÖ Separadores inteligentes (se√ß√µes, par√°grafos, senten√ßas, palavras)
- ‚úÖ Overlap de 200 caracteres (antes: simples)
- ‚úÖ Chunk size otimizado: 800 caracteres (antes: 1000)
- ‚úÖ Respeita quebras naturais do texto
- ‚úÖ Logging detalhado do processo

**Separadores em ordem de prioridade:**
1. `\n\n\n` - Quebras de se√ß√£o
2. `\n\n` - Quebras de par√°grafo
3. `\n` - Quebras de linha
4. `. ` - Senten√ßas
5. `! ` `? ` `; ` `, ` - Pontua√ß√£o
6. ` ` - Palavras
7. `''` - Caracteres (fallback)

### 4Ô∏è‚É£ **Fun√ß√µes Auxiliares** (`text-analysis.ts`)

#### `extractKeywords(text: string): string[]`
Extrai keywords importantes do texto:
- ‚úÖ Medidas e dimens√µes: `1.60 m`, `76 cm`, `2 x 3 m`
- ‚úÖ Termos t√©cnicos: `installation`, `setup`, `requirements`, `specifications`
- ‚úÖ Termos de espa√ßo: `required space`, `minimum space`, `distance`
- ‚úÖ Suporte multi-idioma: PT, EN, DE, ES
- ‚úÖ Pre√ßos e percentuais: `‚Ç¨100`, `R$ 50`, `15%`
- ‚úÖ Frases importantes (2-3 palavras capitalizadas)

#### `detectLanguage(text: string): 'pt' | 'en' | 'de' | 'es' | 'unknown'`
Detecta o idioma do texto automaticamente:
- ‚úÖ Analisa amostra do in√≠cio e meio do documento
- ‚úÖ Conta palavras comuns de cada idioma
- ‚úÖ Retorna idioma com maior score
- ‚úÖ Suporta: Portugu√™s, Ingl√™s, Alem√£o, Espanhol

#### Fun√ß√µes Auxiliares:
- ‚úÖ `hasNumericalData()` - Detecta n√∫meros, medidas, pre√ßos
- ‚úÖ `hasTableStructure()` - Detecta tabelas (Markdown, TSV, alinhadas)
- ‚úÖ `estimatePages()` - Estima n√∫mero de p√°ginas (3000 chars/p√°gina)

### 5Ô∏è‚É£ **Contexto nos Chunks** (`knowledge.service.ts`)

**Antes:**
```typescript
const chunk = chunks[i]
const embedding = await generateEmbedding(chunk)
```

**Depois:**
```typescript
const contextualChunk = `
Documento: ${title}
Tipo: ${contentType}
Idioma: ${language}
Parte ${i + 1} de ${chunks.length}

${chunk}
`.trim()

const embedding = await generateEmbedding(contextualChunk)
```

**Por que isso √© importante?**
- O embedding captura n√£o s√≥ o conte√∫do, mas tamb√©m o CONTEXTO
- A IA sabe de qual documento veio o chunk
- A IA sabe qual √© o tipo de documento (PDF, DOCX, etc.)
- A IA sabe a posi√ß√£o do chunk no documento
- Melhora significativamente a recupera√ß√£o de informa√ß√µes

### 6Ô∏è‚É£ **Metadata Rica**

Cada chunk agora armazena:
```json
{
  "chunkIndex": 0,
  "totalChunks": 35,
  "chunkSize": 526,
  "contextualChunkSize": 620,
  "keywords": ["required space", "1.60 m", "installation", "distance", "platform"],
  "language": "en",
  "hasNumbers": true,
  "hasTable": false,
  "estimatedPages": 6,
  "processedAt": "2025-02-12T10:30:00.000Z",
  "originalFilename": "Pixformance-Fitness-Brochure.pdf",
  "uploadedAt": "2025-02-12T10:30:00.000Z",
  "uploadedBy": "client-id",
  "mimeType": "application/pdf",
  "fileSize": 1234567,
  "contentLength": 18420
}
```

### 7Ô∏è‚É£ **Endpoint de Upload Melhorado**

**Response do endpoint agora retorna:**
```json
{
  "data": {
    "filename": "Pixformance-Fitness-Brochure.pdf",
    "fileSize": 1234567,
    "mimeType": "application/pdf",
    "chunks": 35,
    "totalChars": 18420,
    "avgChunkSize": 526,
    "analysis": {
      "language": "en",
      "hasNumericalData": true,
      "hasTableStructure": false,
      "estimatedPages": 6
    },
    "processing": {
      "chunking": "recursive-character-text-splitter",
      "chunkSize": 800,
      "overlap": 200,
      "embeddingModel": "text-embedding-3-small",
      "embeddingDimensions": 1536
    },
    "metadata": {
      "contextAdded": true,
      "keywordExtraction": true,
      "languageDetection": true,
      "richMetadata": true
    }
  }
}
```

### 8Ô∏è‚É£ **Otimiza√ß√µes de Performance**

- ‚úÖ Rate limiting para OpenAI API (150ms entre requests)
- ‚úÖ Logging de progresso a cada 5 chunks
- ‚úÖ Embedding do chunk contextual (n√£o do chunk original)
- ‚úÖ Armazenamento dual: `content` (original) + `content_with_context`

## üéØ Como Testar

### 1. Fazer upload de um PDF
```bash
curl -X POST \
  http://localhost:3000/api/admin/agents/{agent-id}/knowledge/upload \
  -H "Cookie: nuxt-session=..." \
  -F "file=@Pixformance-Fitness-Brochure.pdf"
```

### 2. Verificar chunks no banco
```sql
SELECT
  id,
  title,
  LEFT(content, 100) as preview,
  metadata->'keywords' as keywords,
  metadata->'language' as language,
  metadata->'chunkIndex' as chunk_num,
  metadata->'totalChunks' as total_chunks
FROM knowledge_base
WHERE agent_config_id = 'xxx'
ORDER BY (metadata->>'chunkIndex')::int
LIMIT 5;
```

### 3. Testar busca h√≠brida
```sql
SELECT * FROM search_knowledge_hybrid(
  'agent-id'::uuid,
  '[0.1, 0.2, ...]'::vector(1536),  -- Query embedding
  ARRAY['required space', 'installation'],  -- Keywords
  10  -- Limit
);
```

## üìä Compara√ß√£o Antes vs Depois

| Aspecto | Antes | Depois |
|---------|-------|--------|
| **Chunking** | Simples por caracteres | RecursiveCharacterTextSplitter |
| **Chunk Size** | 1000 chars | 800 chars |
| **Overlap** | 200 (simples) | 200 (inteligente) |
| **Contexto** | ‚ùå N√£o | ‚úÖ Sim (documento + posi√ß√£o) |
| **Keywords** | ‚ùå N√£o | ‚úÖ Sim (extra√≠das automaticamente) |
| **Idioma** | ‚ùå N√£o | ‚úÖ Detectado automaticamente |
| **Metadata** | B√°sica | Rica (15+ campos) |
| **Busca H√≠brida** | ‚ùå N√£o | ‚úÖ Sim (vetorial + keywords) |
| **Full-text Search** | ‚ùå N√£o | ‚úÖ Sim (√≠ndice GIN) |

## üîç Por que o RAG vai funcionar melhor agora?

### 1. **Chunks mais inteligentes**
   - O RecursiveCharacterTextSplitter respeita quebras naturais do texto
   - N√£o corta frases no meio
   - Overlap inteligente mant√©m contexto entre chunks

### 2. **Contexto nos embeddings**
   - A IA sabe de qual documento veio a informa√ß√£o
   - A IA sabe a posi√ß√£o no documento
   - Embeddings mais precisos e contextuais

### 3. **Keywords ajudam na busca**
   - Busca h√≠brida: vetorial (sem√¢ntica) + keywords (exata)
   - Termos t√©cnicos como "1,60 m" s√£o capturados como keywords
   - Boost autom√°tico para chunks com keywords relevantes

### 4. **Metadata rica permite filtragem**
   - Pode filtrar por idioma
   - Pode priorizar chunks com n√∫meros (para perguntas t√©cnicas)
   - Pode identificar chunks de tabelas

### 5. **Detec√ß√£o de idioma**
   - Sistema multi-idioma autom√°tico
   - Embeddings levam em conta o idioma do documento

## üöÄ Pr√≥ximos Passos Sugeridos

1. **Testar com documentos reais**
   - Fazer upload do PDF do Pixformance novamente
   - Testar perguntas como "qual o espa√ßo necess√°rio?"
   - Validar se os chunks est√£o corretos

2. **Implementar busca h√≠brida no chat**
   - Usar a fun√ß√£o `search_knowledge_hybrid()` no chat
   - Combinar similaridade vetorial + keywords

3. **Adicionar cache de embeddings**
   - Evitar re-processar documentos j√° processados
   - Guardar hash do conte√∫do

4. **Implementar rerank**
   - Ap√≥s busca inicial, re-ordenar resultados
   - Usar modelo de rerank (Cohere, BGE, etc.)

## üêõ Debugging

Se algo n√£o funcionar:

```typescript
// Ver logs detalhados
console.log('Verificar logs no terminal do servidor')

// Ver chunks no banco
SELECT * FROM knowledge_base
WHERE agent_config_id = 'xxx'
ORDER BY created_at DESC
LIMIT 5;

// Ver metadata de um chunk
SELECT
  title,
  jsonb_pretty(metadata)
FROM knowledge_base
WHERE id = 'chunk-id';
```

## üìö Refer√™ncias

- [LangChain Text Splitters](https://js.langchain.com/docs/modules/data_connection/document_transformers/)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)
- [pgvector](https://github.com/pgvector/pgvector)
- [RAG Best Practices](https://www.anthropic.com/research/retrieval-augmented-generation)
